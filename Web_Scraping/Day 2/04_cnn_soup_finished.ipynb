{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Instructions**:\n",
    "\n",
    "  * Believe it or not, CNN's website for [1996: Year in Review](http://edition.cnn.com/EVENTS/1996/year.in.review/) is still alive on the web! We have, however, stored the HTML document as a string in your starter file.\n",
    "\n",
    "  * Your task, should you accept it (and you should), is to use Beautiful Soup to scrape and print the following pieces of information:\n",
    "\n",
    "  1. The title of the webpage\n",
    "\n",
    "  2. All paragraph texts on the page\n",
    "\n",
    "  3. The top 10 headlines for the year. This last one is a bit tricky and may not come out perfectly!\n",
    "\n",
    "* **Hint**:\n",
    "\n",
    "  * For the third task in this activity you will need a means of filtering the data... Perhaps over multiple iterations... With a loop... HINT HINT!\n",
    "\n",
    "* **Bonus**:\n",
    "\n",
    "  * If you finish early, head over to the [Beautful Soup documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to read up on accessing attributes and navigating the DOM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependency\n",
    "import os\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('Resources', 'cnn.html')) as file:\n",
    "    \n",
    "    # Read HTML\n",
    "    html = file.read()\n",
    "\n",
    "    # Create a Beautiful Soup object\n",
    "    soup = bs(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ten Stories From 1996\n"
     ]
    }
   ],
   "source": [
    "# Extract title text\n",
    "title = soup.title.text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "What were the biggest stories of the year?\n",
      "\n",
      "It's a question journalists like to ask themselves at the end of every\n",
      "            year. Now you can join in the process. Here are our selections for the top ten news\n",
      "            stories of 1996.\n",
      "\n",
      "            Disagree with our choices? Then tell us what stories you think were most compelling\n",
      "            in the poll below.\n",
      "\n",
      "\n",
      "\n",
      "What makes a big\n",
      "            story BIG?\n",
      "\n",
      "It depends on your criteria, of course, and your perspective. That's why we offered\n",
      "            a poll to find out what you think.\n",
      "For our list, we polled producers throughout the CNN/Pathfinder family of networks\n",
      "            and publications, and weighed such criteria as a story's long-term implications,\n",
      "            geopolitical significance, user interest, amount of coverage, and old-fashioned newsworthiness.\n",
      "            All these things help make a \"big\" story big.\n",
      "By no means do we think our lists are the final word. Even our polls among CNN\n",
      "            producers turned up a wide variety of responses. The process is meant to encourage\n",
      "            you to reconsider the stories that dominated the media during the past year and determine\n",
      "            for yourself which were mere sensations and which were truly significant.\n",
      "            \n",
      "Â© 1996 Cable News Network, Inc.\n",
      "All Rights Reserved.\n"
     ]
    }
   ],
   "source": [
    "# Print all paragraph texts\n",
    "paras = soup.find_all('p')\n",
    "for para in paras:\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print all ten headlines\n",
    "tds = soup.find_all('td')\n",
    "# A blank list to hold the headlines\n",
    "headlines = []\n",
    "# Loop over td elements\n",
    "for td in tds:\n",
    "    # If td element has an anchor...\n",
    "    if (td.a):\n",
    "        # And the anchor has non-blank text...\n",
    "        if (td.a.text):\n",
    "            # Append the td to the list\n",
    "            headlines.append(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Israel elects Netanyahu\n",
      "Crash of TWA Flight 800\n",
      "Russia elects Yeltsin\n",
      "U.S. elects Clinton\n",
      "Hutu-Tutsi conflict in central Africa\n",
      "Peace, elections in Bosnia\n",
      "U.S. base bombed in Saudi Arabia\n",
      "Centennial Olympic Games\n",
      "Advances against AIDS\n",
      "Unabomb suspect Ted Kaczynski arrested\n"
     ]
    }
   ],
   "source": [
    "# Print only the headlines\n",
    "for x in range(10):\n",
    "    print(headlines[x].text)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
